{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keethu12345/TDS/blob/main/Week_6_Graded_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload all the necessary files."
      ],
      "metadata": {
        "id": "HFT_4yqXRhjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "collapsed": true,
        "id": "waWtf9p7IMoQ",
        "outputId": "8c081a1a-4ed2-45c7-daef-45dfb7f3520e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c56ea50-6973-452f-9ec4-2e7c561cef12\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c56ea50-6973-452f-9ec4-2e7c561cef12\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving discourse-topics.zip to discourse-topics.zip\n",
            "Saving DISTRICT_BOUNDARY.zip to DISTRICT_BOUNDARY.zip\n",
            "Saving eateries.csv to eateries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KnhGIaRxHxo"
      },
      "source": [
        "### Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In eateries.csv, find the distance (in meters) between the eateries. Make sure your method is consistent with the Haversine formula.\n",
        "\n",
        "THE Art Bistro (business ID: 14568), and\n",
        "Broadway Liquors (business ID: 35222)."
      ],
      "metadata": {
        "id": "AsE9mDXmRvqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAV6G-ACxHxu",
        "outputId": "6c0e8031-1ceb-4831-f74d-6ac223292910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Haversine distance: 8087 meters\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "eateries = pd.read_csv('eateries.csv')\n",
        "\n",
        "\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate the Haversine distance between two points on the Earth specified by their latitude and longitude in degrees.\n",
        "\n",
        "    Parameters:\n",
        "    lat1, lon1 : float : Latitude and longitude of the first point.\n",
        "    lat2, lon2 : float : Latitude and longitude of the second point.\n",
        "\n",
        "    Returns:\n",
        "    float : Haversine distance in kilometers.\n",
        "    \"\"\"\n",
        "    # Convert latitude and longitude from degrees to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "\n",
        "    # Differences in coordinates\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "\n",
        "    # Haversine formula\n",
        "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    # Radius of the Earth in kilometers\n",
        "    R = 6371.0\n",
        "\n",
        "    # Distance in kilometers\n",
        "    distance = R * c\n",
        "\n",
        "    return distance\n",
        "\n",
        "lat1, lon1 = eateries[eateries['business_id'] == 14568][['latitude', 'longitude']].values[0]\n",
        "lat2, lon2 = eateries[eateries['business_id'] == 35222][['latitude', 'longitude']].values[0]\n",
        "distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
        "print(f\"Haversine distance: {1000*distance:.0f} meters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FQHUpQCxHxy"
      },
      "source": [
        "### Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In eateries.csv, count the number of pairs of eateries within 184 meters of the each other.\n",
        "\n",
        "You need to find the distance between every pair of eateries and count the number of pairs that are within the given distance."
      ],
      "metadata": {
        "id": "7OiQ9KYRR2Di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs6P2fqZxHxz",
        "outputId": "645f1eae-6c52-4048-ff37-77093313b543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pairs within 184 meters: 36531\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "eateries = pd.read_csv('eateries.csv')\n",
        "\n",
        "# Define the Haversine distance function using NumPy for vectorization\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    R = 6371.0  # Radius of the Earth in kilometers\n",
        "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
        "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
        "\n",
        "    dlat = lat2_rad - lat1_rad[:, np.newaxis]\n",
        "    dlon = lon2_rad - lon1_rad[:, np.newaxis]\n",
        "\n",
        "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad[:, np.newaxis]) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance*1000\n",
        "\n",
        "# Extract coordinates into NumPy arrays\n",
        "latitudes = eateries['latitude'].values\n",
        "longitudes = eateries['longitude'].values\n",
        "business_ids = eateries['business_id'].values\n",
        "\n",
        "# Calculate the distance matrix using vectorized operations\n",
        "distance_matrix = haversine_distance(latitudes, longitudes, latitudes, longitudes)\n",
        "\n",
        "# Create a DataFrame to store distances\n",
        "distance_df = pd.DataFrame(distance_matrix, index=business_ids, columns=business_ids)\n",
        "\n",
        "# Convert to a long format DataFrame for easier analysis\n",
        "distances = distance_df.stack().reset_index()\n",
        "distances.columns = ['business_id_1', 'business_id_2', 'distance']\n",
        "\n",
        "# Filter out self-pairs and pairs beyond the given distance threshold\n",
        "max_distance = 184\n",
        "tril_mask = np.tril(np.ones(distance_matrix.shape), -1).astype(bool)  # Mask for the lower triangle of the matrix\n",
        "distances = distance_matrix[tril_mask]  # Apply mask to get the distances of pairs\n",
        "\n",
        "# Count the number of pairs within the given distance\n",
        "num_pairs_within_distance = np.sum(distances <= max_distance)\n",
        "\n",
        "print(f\"Number of pairs within {max_distance} meters: {num_pairs_within_distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJURlfbxHx1"
      },
      "source": [
        "### Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In eateries.csv, count the number of pairs of eateries within 1092 meters of the each other.\n",
        "\n",
        "You need to find the distance between every pair of eateries and count the number of pairs that are within the given distance."
      ],
      "metadata": {
        "id": "0Wbpq7XdR7PC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKFDH0jBxHx2",
        "outputId": "53c68c10-69eb-4bef-fb50-aed7df6c6640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pairs within 1092 meters: 629235\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "eateries = pd.read_csv('eateries.csv')\n",
        "\n",
        "# Define the Haversine distance function using NumPy for vectorization\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    R = 6371.0  # Radius of the Earth in kilometers\n",
        "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
        "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
        "\n",
        "    dlat = lat2_rad - lat1_rad[:, np.newaxis]\n",
        "    dlon = lon2_rad - lon1_rad[:, np.newaxis]\n",
        "\n",
        "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad[:, np.newaxis]) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance*1000\n",
        "\n",
        "# Extract coordinates into NumPy arrays\n",
        "latitudes = eateries['latitude'].values\n",
        "longitudes = eateries['longitude'].values\n",
        "business_ids = eateries['business_id'].values\n",
        "\n",
        "# Calculate the distance matrix using vectorized operations\n",
        "distance_matrix = haversine_distance(latitudes, longitudes, latitudes, longitudes)\n",
        "\n",
        "# Create a DataFrame to store distances\n",
        "distance_df = pd.DataFrame(distance_matrix, index=business_ids, columns=business_ids)\n",
        "\n",
        "# Convert to a long format DataFrame for easier analysis\n",
        "distances = distance_df.stack().reset_index()\n",
        "distances.columns = ['business_id_1', 'business_id_2', 'distance']\n",
        "\n",
        "max_distance = 1092\n",
        "tril_mask = np.tril(np.ones(distance_matrix.shape), -1).astype(bool)  # Mask for the lower triangle of the matrix\n",
        "distances = distance_matrix[tril_mask]  # Apply mask to get the distances of pairs\n",
        "\n",
        "# Count the number of pairs within the given distance\n",
        "num_pairs_within_distance = np.sum(distances <= max_distance)\n",
        "\n",
        "print(f\"Number of pairs within {max_distance} meters: {num_pairs_within_distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQTJlbHixHx4"
      },
      "source": [
        "### Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to this District Boundaries Shapefile, which of these points below is inside:\n",
        "\n",
        "\n",
        "DISTRICT: BHAND>RA, STATE: MAH>R>SHTRA\n",
        "\n",
        "Note: The Shapefile has poorly formatted data. District names and state names have minor errors. Ignore that."
      ],
      "metadata": {
        "id": "1TbgZGPoR-iy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kueTFD8zxHx5",
        "outputId": "fc1e4d10-730e-429d-f332-dda26f903fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DISTRICT_BOUNDARY.zip\n",
            "(79.9348, 21.0826) is within given region\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "!unzip -n DISTRICT_BOUNDARY.zip\n",
        "# Path to the shapefile\n",
        "shapefile_path = 'DISTRICT_BOUNDARY.shp'\n",
        "\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "district_name = 'BHAND>RA'\n",
        "state_name = 'MAH>R>SHTRA'\n",
        "filtered_gdf = gdf[(gdf['District'] == district_name) & (gdf['STATE'] == state_name)]\n",
        "district_shape = filtered_gdf.geometry.iloc[0]\n",
        "\n",
        "points = [(79.3532, 21.6494),\n",
        "          (79.7454, 21.9209),\n",
        "          (79.3444, 20.3425),\n",
        "          (79.9348, 21.0826)]\n",
        "for point in points:\n",
        "    point_geom = Point(point[0], point[1])\n",
        "    if point_geom.within(district_shape):\n",
        "        print(f\"{point} is within given region\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qe_0l7WxHx6"
      },
      "source": [
        "### Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this District Boundaries Shapefile, what percentage of the area of:\n",
        "\n",
        "DISTRICT: WARANGAL (URBAN), STATE: TELANG>NA\n",
        "\n",
        "is intersected by the box covering Latitude: 17.9188 to 18.0778, Longitude: 79.2894 to 79.6293?"
      ],
      "metadata": {
        "id": "GDh9NWM2SBgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGXFQGEtxHx7",
        "outputId": "c8ae39ab-4ddf-42bf-a5e8-80adfb2a9562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DISTRICT_BOUNDARY.zip\n",
            "Percentage of the area of WARANGAL (URBAN) intersected by the bounding box: 52.45%\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import box\n",
        "\n",
        "!unzip -n DISTRICT_BOUNDARY.zip\n",
        "# Path to the shapefile\n",
        "shapefile_path = 'DISTRICT_BOUNDARY.shp'\n",
        "\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Filter the district\n",
        "district_name = 'WARANGAL (URBAN)'\n",
        "state_name = 'TELANG>NA'\n",
        "filtered_gdf = gdf[(gdf['District'] == district_name) & (gdf['STATE'] == state_name)]\n",
        "\n",
        "# If found, extract the district geometry\n",
        "district_shape = filtered_gdf.geometry.iloc[0]\n",
        "\n",
        "# Define the bounding box coordinates\n",
        "lat_min, lat_max = 17.9188 , 18.0778\n",
        "lon_min, lon_max = 79.2894 , 79.6293\n",
        "\n",
        "# Create a bounding box polygon\n",
        "bounding_box = box(lon_min, lat_min, lon_max, lat_max)\n",
        "\n",
        "# Calculate the intersection between the district and the bounding box\n",
        "intersection = district_shape.intersection(bounding_box)\n",
        "\n",
        "# Calculate the areas\n",
        "district_area = district_shape.area\n",
        "intersection_area = intersection.area\n",
        "\n",
        "# Calculate the percentage of the district's area that is intersected by the bounding box\n",
        "percentage_intersected = (intersection_area / district_area) * 100\n",
        "\n",
        "print(f\"Percentage of the area of {district_name} intersected by the bounding box: {percentage_intersected:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKuxKI5UxHx7"
      },
      "source": [
        "### Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This Discourse topics collection lists topics and posters for each topic.\n",
        "\n",
        "How many users (i.e. posters[*][\"username\"]) posted in more topics than royce did in this dataset?"
      ],
      "metadata": {
        "id": "EEvd3gBWSMHk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISDJAuhExHx8",
        "outputId": "964bf9c3-49b4-435c-9031-f9b957ec41d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  discourse-topics.zip\n",
            "  inflating: discourse-topics.json   \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "497"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!unzip -n discourse-topics.zip\n",
        "# Load the JSON file\n",
        "topics=pd.read_json('discourse-topics.json')\n",
        "\n",
        "# Initialize a dictionary to hold the count of topics for each username\n",
        "username_topic_count = {}\n",
        "\n",
        "# Iterate over each row in the 'topics' DataFrame\n",
        "for posters in topics['posters']:\n",
        "    # Extract the usernames from the posters column\n",
        "    usernames = [poster['username'] for poster in posters]\n",
        "\n",
        "    # Update the count for each username\n",
        "    for username in usernames:\n",
        "        if username in username_topic_count:\n",
        "            username_topic_count[username] += 1\n",
        "        else:\n",
        "            username_topic_count[username] = 1\n",
        "\n",
        "# Convert the dictionary to a DataFrame for easier analysis (optional)\n",
        "username_topic_count_df = pd.DataFrame(\n",
        "    list(username_topic_count.items()), columns=['username', 'topic_count']\n",
        ")\n",
        "target_username = 'royce'\n",
        "target_topic_count = username_topic_count_df[username_topic_count_df['username']==target_username]['topic_count'].values[0]\n",
        "username_topic_count_df[(username_topic_count_df['topic_count'] > target_topic_count)].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZjggnrLxHx9"
      },
      "source": [
        "### Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Discourse topics collection lists topics and posters for each topic.\n",
        "\n",
        "21f2000436 and Nikita collaborated on 20 topics. How many pairs of users have collaborated on more topics than they have?"
      ],
      "metadata": {
        "id": "Wjli16W9SQXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUTz_9TcxHx9",
        "outputId": "f579f876-ddad-4378-f9b2-3291443cec42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  discourse-topics.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "!unzip -n discourse-topics.zip\n",
        "# Load the JSON file\n",
        "topics=pd.read_json('discourse-topics.json')\n",
        "\n",
        "# Extract all unique usernames\n",
        "unique_usernames = set()\n",
        "for posters in topics['posters']:\n",
        "    for poster in posters:\n",
        "        unique_usernames.add(poster['username'])\n",
        "unique_usernames = list(unique_usernames)\n",
        "\n",
        "# Create a dictionary to map usernames to matrix column indices\n",
        "user_index = {username: idx for idx, username in enumerate(unique_usernames)}\n",
        "\n",
        "# Initialize lists to create a sparse matrix\n",
        "row_indices = []\n",
        "col_indices = []\n",
        "data = []\n",
        "\n",
        "# Populate the indices and data for the sparse matrix\n",
        "for i, posters in enumerate(topics['posters']):\n",
        "    for poster in posters:\n",
        "        user_idx = user_index[poster['username']]\n",
        "        row_indices.append(i)\n",
        "        col_indices.append(user_idx)\n",
        "        data.append(1)\n",
        "\n",
        "# Create the sparse matrix\n",
        "user_topic_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(len(topics), len(unique_usernames)))\n",
        "\n",
        "# Compute the matrix multiplication using sparse matrices\n",
        "collaboration_matrix = user_topic_matrix.T @ user_topic_matrix\n",
        "\n",
        "# Initialize a list to hold the collaboration pairs\n",
        "collaboration_pairs = []\n",
        "\n",
        "# Convert the sparse matrix to COO format\n",
        "collaboration_matrix_coo = collaboration_matrix.tocoo()\n",
        "\n",
        "# Iterate through the non-zero elements of the COO matrix\n",
        "for i, j, count in zip(collaboration_matrix_coo.row, collaboration_matrix_coo.col, collaboration_matrix_coo.data):\n",
        "    if i != j:\n",
        "        username_1 = unique_usernames[i]\n",
        "        username_2 = unique_usernames[j]\n",
        "        collaboration_pairs.append((username_1, username_2, count))\n",
        "\n",
        "# Convert the collaboration pairs to a DataFrame\n",
        "collaboration_count_df = pd.DataFrame(collaboration_pairs, columns=['username_1', 'username_2', 'collaboration_count'])\n",
        "\n",
        "def count_collaborations_more_than(count):\n",
        "    return collaboration_count_df[collaboration_count_df['collaboration_count'] > count].shape[0]\n",
        "\n",
        "count_collaborations_more_than(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNX9s9JCxHx-"
      },
      "source": [
        "### Q8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Discourse topics collection lists topics and posters for each topic.\n",
        "\n",
        "The shortest path between 2 users A, B is when A has co-posted on a topic with X, and X has co-posted with Y, ... who has co-posted with B; and there is no shorter path between them.\n",
        "\n",
        "Which of these users is in any of the shortest paths between 24dp2000010 and 24ds1000116?"
      ],
      "metadata": {
        "id": "puAZ-GMnSYa8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrDxYiKvxHx-",
        "outputId": "2113c927-71ab-476f-8685-47465afa2638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  discourse-topics.zip\n",
            "['24dp2000010', '22F3002354', 'shriaviator', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', '22f3002293', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', '23f3002277', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', '22f3000983', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', 'Anand', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', '23f3003786', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', '24f1000656', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', 'Karthik_POD', 'deepbist', '24ds1000116']\n",
            "['24dp2000010', '22F3002354', 'Himanshu207', 'deepbist', '24ds1000116']\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "!unzip -n discourse-topics.zip\n",
        "# Load the JSON file\n",
        "topics=pd.read_json('discourse-topics.json')\n",
        "\n",
        "# Initialize the graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Iterate over each topic\n",
        "for posters in topics['posters']:\n",
        "    # Extract the usernames of the posters\n",
        "    usernames = [poster['username'] for poster in posters]\n",
        "\n",
        "    # Add edges between each pair of users who posted in the same topic\n",
        "    for username1, username2 in combinations(usernames, 2):\n",
        "        G.add_edge(username1, username2)\n",
        "\n",
        "all_paths = nx.all_shortest_paths(G, '24dp2000010', '24ds1000116')\n",
        "for path in all_paths:\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kncCKmdaxHx-"
      },
      "source": [
        "### Q9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This Discourse topics collection lists topics and posters for each topic.\n",
        "\n",
        "The shortest path between 2 users A, B is when A has co-posted on a topic with X, and X has co-posted with Y, ... who has co-posted with B; and there is no shorter path between them.\n",
        "\n",
        "How many such shortest paths exist between Minato_Yuki and viks?"
      ],
      "metadata": {
        "id": "nHo9lE4ySbQB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn2fNeijxHx_",
        "outputId": "acfc3dbc-3204-4ac3-ffaa-ed011e1fa37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  discourse-topics.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "!unzip -n discourse-topics.zip\n",
        "# Load the JSON file\n",
        "topics=pd.read_json('discourse-topics.json')\n",
        "\n",
        "# Initialize the graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Iterate over each topic\n",
        "for posters in topics['posters']:\n",
        "    # Extract the usernames of the posters\n",
        "    usernames = [poster['username'] for poster in posters]\n",
        "\n",
        "    # Add edges between each pair of users who posted in the same topic\n",
        "    for username1, username2 in combinations(usernames, 2):\n",
        "        G.add_edge(username1, username2)\n",
        "\n",
        "all_paths = list(nx.all_shortest_paths(G, 'Minato_Yuki', 'viks'))\n",
        "len(all_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEMnq_3PxHx_"
      },
      "source": [
        "### Q10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Discourse topics collection lists topics and posters for each topic.\n",
        "\n",
        "The shortest path between 2 users A, B is when A has co-posted on a topic with X, and X has co-posted with Y, ... who has co-posted with B; and there is no shorter path between them.\n",
        "\n",
        "How many such shortest paths exist between 23f2003893 and KVKrishnaR?"
      ],
      "metadata": {
        "id": "2rHg28dCSfHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PDLmI_3xHyA",
        "outputId": "28ebbcf0-34d1-4d56-ebec-8ecd716cae8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  discourse-topics.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "!unzip -n discourse-topics.zip\n",
        "# Load the JSON file\n",
        "topics=pd.read_json('discourse-topics.json')\n",
        "\n",
        "# Initialize the graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Iterate over each topic\n",
        "for posters in topics['posters']:\n",
        "    # Extract the usernames of the posters\n",
        "    usernames = [poster['username'] for poster in posters]\n",
        "\n",
        "    # Add edges between each pair of users who posted in the same topic\n",
        "    for username1, username2 in combinations(usernames, 2):\n",
        "        G.add_edge(username1, username2)\n",
        "\n",
        "all_paths = list(nx.all_shortest_paths(G, '23f2003893', 'KVKrishnaR'))\n",
        "len(all_paths)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}